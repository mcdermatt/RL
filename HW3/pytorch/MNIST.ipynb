{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demo NN using builtin datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "import time\n",
    "\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download datasets locally\n",
    "train = datasets.MNIST(\"\", train = True, download = False,\n",
    "                      transform = transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "test = datasets.MNIST(\"\", train = False, download = False,\n",
    "                      transform = transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batches - don't want to give the algo all the data at once or it will not work as well on new data\n",
    "#   usually best batch size is between 8 and 64\n",
    "trainset = torch.utils.data.DataLoader(train, batch_size = 10, shuffle = True)\n",
    "testset = torch.utils.data.DataLoader(test, batch_size = 10, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([2, 8, 3, 8, 0, 3, 3, 9, 0, 4])]\n"
     ]
    }
   ],
   "source": [
    "for data in trainset:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2)\n"
     ]
    }
   ],
   "source": [
    "x, y = data[0][0], data[1][0]\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(data[0][0].shape)\n",
    "\n",
    "#torch.Size([1, 28, 28])\n",
    "#   size of image is actually an extra dimension\n",
    "#   extra 1 dimension is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x297409a17c8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(data[0][0].view(28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balancing is SUPER important-\n",
    "if 60% of our training data is a \"3\" then a set of weights that always guesses 3 will reach a local max and training will fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "counter_dict = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0, 8:0, 9:0}\n",
    "\n",
    "for data in trainset:\n",
    "    Xs, ys = data\n",
    "    for y in ys:\n",
    "        counter_dict[int(y)] += 1\n",
    "        total += 1\n",
    "        \n",
    "print(counter_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 9.871666666666666\n",
      "1: 11.236666666666666\n",
      "2: 9.93\n",
      "3: 10.218333333333334\n",
      "4: 9.736666666666666\n",
      "5: 9.035\n",
      "6: 9.863333333333333\n",
      "7: 10.441666666666666\n",
      "8: 9.751666666666667\n",
      "9: 9.915000000000001\n"
     ]
    }
   ],
   "source": [
    "for i in counter_dict:\n",
    "    print(f\"{i}: {counter_dict[i]/total*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module): #create class Net and inherit from nn.Module\n",
    "    def __init__(self):\n",
    "        super().__init__() #need to run this because the init func of nn.Module is not run from inherit\n",
    "       \n",
    "        #Linear is a simple flat fuly connected\n",
    "        self.fc1 = nn.Linear(784, 64) #when images are flattened they are 28*28 = 784 long\n",
    "        self.fc2 = nn.Linear(64, 64)  #arbitrarily choosing 64 nodes for hidden layers\n",
    "        self.fc3 = nn.Linear(64, 64) \n",
    "        self.fc4 = nn.Linear(64, 10)  #output layer is size 10 for digits 0-9\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #F.relu is rectified linear activation func\n",
    "        #   activation func is sigmoid- keeps output from exploding\n",
    "        #   attempt to model whether neuron is or is not firing\n",
    "        x = F.relu(self.fc1(x)) \n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        #for output we only want one neuron to be fully fired\n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim = 1) #since I am working with flat linear funcs this dim will always = 1\n",
    "        \n",
    "        \n",
    "net = Net()\n",
    "# print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.3301, -2.1851, -2.3650, -2.2539, -2.3776, -2.3530, -2.1667, -2.4040,\n",
      "         -2.2446, -2.3797]], grad_fn=<LogSoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand((28,28)) #fake input image\n",
    "X = X.view(-1,28*28)    #-1 specifies that input will be of unknown shape\n",
    "output = net(X)\n",
    "print(output) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0372, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0152, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0185, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "#loss is a measure of how wrong is our model\n",
    "#   loss should trend downward over time\n",
    "# Optimizer adjusts weights bit by bit over time (according to learning rate) to lower loss\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr = 0.001) #net.parmeters controls what stuff in net() is adjusted (default is everything)\n",
    "\n",
    "#decaying learning rate -> lr decreases over time to prevent overshooting\n",
    "\n",
    "EPOCHS = 3 #full passes through dataset\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for data in trainset:\n",
    "        #data is a batch of featuresets and labels\n",
    "        X, y = data\n",
    "        net.zero_grad()\n",
    "        output = net(X.view(-1,28*28))\n",
    "        loss = F.nll_loss(output, y) #usually use mean^2 error if data is onehot vector\n",
    "        \n",
    "        #magic backpropogation algorithm\n",
    "        loss.backward()\n",
    "        \n",
    "        #adjusts weights\n",
    "        optimizer.step()\n",
    "        \n",
    "    print (loss)\n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.971\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    #net.train() and net.eval() are depreciated ways of changing the mode\n",
    "    for data in testset:\n",
    "        X, y = data\n",
    "        output = net(X.view(-1, 784))\n",
    "        \n",
    "        for idx, i in enumerate(output):\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct += 1\n",
    "                \n",
    "            total += 1\n",
    "print(\"Accuracy: \", round(correct/total, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training took  65.26460933685303  seconds\n"
     ]
    }
   ],
   "source": [
    "finish = time.time()\n",
    "print(\"training took \", finish-start, \" seconds\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
